# Synthetic data generation for embedding model fine-tuning (workshop on MLPrague 2025)

## Abstract
Retrieving information from documents in non-English and domain-specific languages presents a challenge for many organizations. While general embedding models are powerful, they often fall short when dealing with specialized terminology not encountered in their training data. This workshop offers a practical approach to addressing these issues: using a combination of real and synthetic data to build robust datasets for fine-tuning open embedding models.
The workshop consists of two parts. First, we provide an overview of embedding models, fine-tuning techniques, and methods for generating synthetic data tailored to these approaches. In the second part, participants will engage in a hands-on session to generate synthetic data for fine-tuning their own models.

## Setup
All of the code was run in Google Colab, which provides an easy-to-set-up environment with access to Gemini LLMs.
